{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9919fdb",
   "metadata": {},
   "source": [
    "1. Scrape  the  \n",
    "details  of  \n",
    "most  viewed  videos  on  \n",
    "YouTube  \n",
    "from  Wikipedia.  \n",
    "Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:  A) \n",
    "Rank   \n",
    "B) Name   \n",
    "C) Artist   \n",
    "D) Upload date   \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fa590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f4179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Rank  \\\n",
      "0                             \"Baby Shark Dance\"[6]   \n",
      "1                                    \"Despacito\"[9]   \n",
      "2                        \"Johny Johny Yes Papa\"[17]   \n",
      "3                                   \"Bath Song\"[18]   \n",
      "4                                \"Shape of You\"[19]   \n",
      "5                               \"See You Again\"[22]   \n",
      "6                           \"Wheels on the Bus\"[27]   \n",
      "7                 \"Phonics Song with Two Words\"[28]   \n",
      "8                                 \"Uptown Funk\"[29]   \n",
      "9   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
      "10                              \"Gangnam Style\"[31]   \n",
      "11   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
      "12                             \"Dame Tu Cosita\"[37]   \n",
      "13                                     \"Axel F\"[38]   \n",
      "14                                      \"Sugar\"[39]   \n",
      "15                             \"Counting Stars\"[40]   \n",
      "16                        \"Baa Baa Black Sheep\"[41]   \n",
      "17                                       \"Roar\"[42]   \n",
      "18                             \"Lakdi Ki Kathi\"[43]   \n",
      "19           \"Waka Waka (This Time for Africa)\"[44]   \n",
      "20                                      \"Sorry\"[45]   \n",
      "21                          \"Thinking Out Loud\"[46]   \n",
      "22          \"Humpty the train on a fruits ride\"[47]   \n",
      "23                      \"Shree Hanuman Chalisa\"[48]   \n",
      "24                                 \"Dark Horse\"[49]   \n",
      "25                                    \"Perfect\"[50]   \n",
      "26                                 \"Let Her Go\"[51]   \n",
      "27                                      \"Faded\"[52]   \n",
      "28                             \"Girls Like You\"[53]   \n",
      "29                                    \"Lean On\"[54]   \n",
      "\n",
      "                                                 Name Artist Upload Date  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories  14.09         [A]   \n",
      "1                                          Luis Fonsi   8.38         [B]   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.87               \n",
      "3                          Cocomelon - Nursery Rhymes   6.62               \n",
      "4                                          Ed Sheeran   6.20         [C]   \n",
      "5                                         Wiz Khalifa   6.17         [D]   \n",
      "6                          Cocomelon - Nursery Rhymes   5.88               \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs   5.70               \n",
      "8                                         Mark Ronson   5.15               \n",
      "9                                         Miroshka TV   5.07               \n",
      "10                                                Psy   5.05         [E]   \n",
      "11                                         Get Movies   4.58               \n",
      "12                                      Ultra Records   4.55               \n",
      "13                                         Crazy Frog   4.34               \n",
      "14                                           Maroon 5   4.00               \n",
      "15                                        OneRepublic   3.97               \n",
      "16                         Cocomelon - Nursery Rhymes   3.96               \n",
      "17                                         Katy Perry   3.96               \n",
      "18                                       Jingle Toons   3.91               \n",
      "19                                            Shakira   3.85               \n",
      "20                                      Justin Bieber   3.77               \n",
      "21                                         Ed Sheeran   3.73               \n",
      "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.73               \n",
      "23                              T-Series Bhakti Sagar   3.69               \n",
      "24                                         Katy Perry   3.67               \n",
      "25                                         Ed Sheeran   3.67               \n",
      "26                                          Passenger   3.61               \n",
      "27                                        Alan Walker   3.59               \n",
      "28                                           Maroon 5   3.56               \n",
      "29                               Major Lazer Official   3.55               \n",
      "\n",
      "                Views  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4    January 30, 2017  \n",
      "5       April 6, 2015  \n",
      "6        May 24, 2018  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9   February 27, 2018  \n",
      "10      July 15, 2012  \n",
      "11   January 31, 2012  \n",
      "12      April 5, 2018  \n",
      "13      June 16, 2009  \n",
      "14   January 14, 2015  \n",
      "15       May 31, 2013  \n",
      "16      June 25, 2018  \n",
      "17  September 5, 2013  \n",
      "18      June 14, 2018  \n",
      "19       June 4, 2010  \n",
      "20   October 22, 2015  \n",
      "21    October 7, 2014  \n",
      "22   January 26, 2018  \n",
      "23       May 10, 2011  \n",
      "24  February 20, 2014  \n",
      "25   November 9, 2017  \n",
      "26      July 25, 2012  \n",
      "27   December 3, 2015  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "video_rank = []\n",
    "video_name = []\n",
    "video_artist = []\n",
    "video_upload_date = []\n",
    "video_views = []\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5:  \n",
    "        video_rank.append(columns[0].text.strip())\n",
    "        video_name.append(columns[1].text.strip())\n",
    "        video_artist.append(columns[2].text.strip())\n",
    "        video_upload_date.append(columns[4].text.strip())\n",
    "        video_views.append(columns[3].text.strip())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Rank\": video_rank,\n",
    "    \"Name\": video_name,\n",
    "    \"Artist\": video_artist,\n",
    "    \"Upload Date\": video_upload_date,\n",
    "    \"Views\": video_views\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100b7be",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.   \n",
    "Url = https://www.bcci.tv/.   \n",
    "You need to find following details:   \n",
    "A) Series   \n",
    "B) Place   \n",
    "C) Date   \n",
    "D) Time   \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31518727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Rank  \\\n",
      "0                             \"Baby Shark Dance\"[6]   \n",
      "1                                    \"Despacito\"[9]   \n",
      "2                        \"Johny Johny Yes Papa\"[17]   \n",
      "3                                   \"Bath Song\"[18]   \n",
      "4                                \"Shape of You\"[19]   \n",
      "5                               \"See You Again\"[22]   \n",
      "6                           \"Wheels on the Bus\"[27]   \n",
      "7                 \"Phonics Song with Two Words\"[28]   \n",
      "8                                 \"Uptown Funk\"[29]   \n",
      "9   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
      "10                              \"Gangnam Style\"[31]   \n",
      "11   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
      "12                             \"Dame Tu Cosita\"[37]   \n",
      "13                                     \"Axel F\"[38]   \n",
      "14                                      \"Sugar\"[39]   \n",
      "15                             \"Counting Stars\"[40]   \n",
      "16                        \"Baa Baa Black Sheep\"[41]   \n",
      "17                                       \"Roar\"[42]   \n",
      "18                             \"Lakdi Ki Kathi\"[43]   \n",
      "19           \"Waka Waka (This Time for Africa)\"[44]   \n",
      "20                                      \"Sorry\"[45]   \n",
      "21                          \"Thinking Out Loud\"[46]   \n",
      "22          \"Humpty the train on a fruits ride\"[47]   \n",
      "23                      \"Shree Hanuman Chalisa\"[48]   \n",
      "24                                 \"Dark Horse\"[49]   \n",
      "25                                    \"Perfect\"[50]   \n",
      "26                                 \"Let Her Go\"[51]   \n",
      "27                                      \"Faded\"[52]   \n",
      "28                             \"Girls Like You\"[53]   \n",
      "29                                    \"Lean On\"[54]   \n",
      "\n",
      "                                                 Name Artist Upload Date  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories  14.09         [A]   \n",
      "1                                          Luis Fonsi   8.38         [B]   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.87               \n",
      "3                          Cocomelon - Nursery Rhymes   6.62               \n",
      "4                                          Ed Sheeran   6.20         [C]   \n",
      "5                                         Wiz Khalifa   6.17         [D]   \n",
      "6                          Cocomelon - Nursery Rhymes   5.88               \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs   5.70               \n",
      "8                                         Mark Ronson   5.15               \n",
      "9                                         Miroshka TV   5.07               \n",
      "10                                                Psy   5.05         [E]   \n",
      "11                                         Get Movies   4.58               \n",
      "12                                      Ultra Records   4.55               \n",
      "13                                         Crazy Frog   4.34               \n",
      "14                                           Maroon 5   4.00               \n",
      "15                                        OneRepublic   3.97               \n",
      "16                         Cocomelon - Nursery Rhymes   3.96               \n",
      "17                                         Katy Perry   3.96               \n",
      "18                                       Jingle Toons   3.91               \n",
      "19                                            Shakira   3.85               \n",
      "20                                      Justin Bieber   3.77               \n",
      "21                                         Ed Sheeran   3.73               \n",
      "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.73               \n",
      "23                              T-Series Bhakti Sagar   3.69               \n",
      "24                                         Katy Perry   3.67               \n",
      "25                                         Ed Sheeran   3.67               \n",
      "26                                          Passenger   3.61               \n",
      "27                                        Alan Walker   3.59               \n",
      "28                                           Maroon 5   3.56               \n",
      "29                               Major Lazer Official   3.55               \n",
      "\n",
      "                Views  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4    January 30, 2017  \n",
      "5       April 6, 2015  \n",
      "6        May 24, 2018  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9   February 27, 2018  \n",
      "10      July 15, 2012  \n",
      "11   January 31, 2012  \n",
      "12      April 5, 2018  \n",
      "13      June 16, 2009  \n",
      "14   January 14, 2015  \n",
      "15       May 31, 2013  \n",
      "16      June 25, 2018  \n",
      "17  September 5, 2013  \n",
      "18      June 14, 2018  \n",
      "19       June 4, 2010  \n",
      "20   October 22, 2015  \n",
      "21    October 7, 2014  \n",
      "22   January 26, 2018  \n",
      "23       May 10, 2011  \n",
      "24  February 20, 2014  \n",
      "25   November 9, 2017  \n",
      "26      July 25, 2012  \n",
      "27   December 3, 2015  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "video_rank = []\n",
    "video_name = []\n",
    "video_artist = []\n",
    "video_upload_date = []\n",
    "video_views = []\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5: \n",
    "        video_rank.append(columns[0].text.strip())\n",
    "        video_name.append(columns[1].text.strip())\n",
    "        video_artist.append(columns[2].text.strip())\n",
    "        video_upload_date.append(columns[4].text.strip())\n",
    "        video_views.append(columns[3].text.strip())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Rank\": video_rank,\n",
    "    \"Name\": video_name,\n",
    "    \"Artist\": video_artist,\n",
    "    \"Upload Date\": video_upload_date,\n",
    "    \"Views\": video_views\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f2704b",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.   \n",
    "Url = http://statisticstimes.com/   \n",
    "You have to find following details: A) Rank   \n",
    "B) State   \n",
    "C) GSDP(18-19)- at current prices   \n",
    "D) GSDP(19-20)- at current prices   \n",
    "E) Share(18-19)   \n",
    "F) GDP($ billion)   \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2704fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economy link not found. Please check the website structure.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"http://statisticstimes.com/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "economy_link = soup.find(\"a\", string=\"Economy\")\n",
    "if economy_link:\n",
    "    economy_url = f\"{url}{economy_link['href']}\"\n",
    "\n",
    "    economy_response = requests.get(economy_url)\n",
    "    economy_html_content = economy_response.content\n",
    "\n",
    "    economy_soup = BeautifulSoup(economy_html_content, \"html.parser\")\n",
    "\n",
    "    gdp_table = economy_soup.find(\"table\", {\"id\": \"table_id\"})\n",
    "\n",
    "    rank = []\n",
    "    state = []\n",
    "    gdp_18_19 = []\n",
    "    gdp_19_20 = []\n",
    "    share_18_19 = []\n",
    "    gdp_billion = []\n",
    "\n",
    "    for row in gdp_table.find_all(\"tr\")[1:]:\n",
    "        columns = row.find_all(\"td\")\n",
    "        rank.append(columns[0].text.strip())\n",
    "        state.append(columns[1].text.strip())\n",
    "        gdp_18_19.append(columns[2].text.strip())\n",
    "        gdp_19_20.append(columns[3].text.strip())\n",
    "        share_18_19.append(columns[4].text.strip())\n",
    "        gdp_billion.append(columns[5].text.strip())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Rank\": rank,\n",
    "        \"State\": state,\n",
    "        \"GSDP (18-19)\": gdp_18_19,\n",
    "        \"GSDP (19-20)\": gdp_19_20,\n",
    "        \"Share (18-19)\": share_18_19,\n",
    "        \"GDP ($ billion)\": gdp_billion\n",
    "    })\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Economy link not found. Please check the website structure.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167e1d8",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.   \n",
    "Url = https://github.com/   \n",
    "You have to find the following details:   \n",
    "A) Repository title   \n",
    "B) Repository description   \n",
    "C) Contributors count   \n",
    "D) Language used  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94437eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending link not found. Please check the website structure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_17224\\3728458943.py:16: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  trending_link = soup.find(\"a\", text=\"Trending\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "github_url = \"https://github.com/\"\n",
    "\n",
    "response = requests.get(github_url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "trending_link = soup.find(\"a\", text=\"Trending\")\n",
    "if trending_link:\n",
    "    trending_url = f\"{github_url}{trending_link['href']}\"\n",
    "\n",
    "    trending_response = requests.get(trending_url)\n",
    "    trending_html_content = trending_response.content\n",
    "\n",
    "    trending_soup = BeautifulSoup(trending_html_content, \"html.parser\")\n",
    "\n",
    "    repo_title = []\n",
    "    repo_description = []\n",
    "    contributors_count = []\n",
    "    language_used = []\n",
    "\n",
    "    for card in trending_soup.find_all(\"article\", class_=\"Box-row\"):\n",
    "        repo_title.append(card.find(\"h1\").text.strip())\n",
    "        repo_description.append(card.find(\"p\", class_=\"mb-1\").text.strip())\n",
    "        contributors_count.append(card.find(\"a\", class_=\"muted-link\").text.strip())\n",
    "        language_used.append(card.find(\"span\", itemprop=\"programmingLanguage\").text.strip())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Repository Title\": repo_title,\n",
    "        \"Repository Description\": repo_description,\n",
    "        \"Contributors Count\": contributors_count,\n",
    "        \"Language Used\": language_used\n",
    "    })\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Trending link not found. Please check the website structure.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8752c",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the \n",
    "following details:   \n",
    "A) Song name   \n",
    "B) Artist name   \n",
    "C) Last week rank   \n",
    "D) Peak rank   \n",
    "E) Weeks on board   \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccd51a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot 100 link not found. Please check the website structure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_17224\\1711346779.py:16: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  hot_100_link = soup.find(\"a\", text=\"Hot 100\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "billboard_url = \"https://www.billboard.com/\"\n",
    "\n",
    "response = requests.get(billboard_url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "hot_100_link = soup.find(\"a\", text=\"Hot 100\")\n",
    "if hot_100_link:\n",
    "    hot_100_url = f\"{billboard_url}{hot_100_link['href']}\"\n",
    "\n",
    "    hot_100_response = requests.get(hot_100_url)\n",
    "    hot_100_html_content = hot_100_response.content\n",
    "\n",
    "    hot_100_soup = BeautifulSoup(hot_100_html_content, \"html.parser\")\n",
    "\n",
    "    song_name = []\n",
    "    artist_name = []\n",
    "    last_week_rank = []\n",
    "    peak_rank = []\n",
    "    weeks_on_board = []\n",
    "\n",
    "    for row in hot_100_soup.find_all(\"div\", class_=\"chart-list-item\"):\n",
    "        song_name.append(row.find(\"span\", class_=\"chart-list-item__title-text\").text.strip())\n",
    "        artist_name.append(row.find(\"div\", class_=\"chart-list-item__artist\").text.strip())\n",
    "        last_week_rank.append(row.find(\"div\", class_=\"chart-list-item__last-week\").text.strip())\n",
    "        peak_rank.append(row.find(\"div\", class_=\"chart-list-item__weeks-at-one\").text.strip())\n",
    "        weeks_on_board.append(row.find(\"div\", class_=\"chart-list-item__weeks-on-chart\").text.strip())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Song Name\": song_name,\n",
    "        \"Artist Name\": artist_name,\n",
    "        \"Last Week Rank\": last_week_rank,\n",
    "        \"Peak Rank\": peak_rank,\n",
    "        \"Weeks on Board\": weeks_on_board\n",
    "    })\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Hot 100 link not found. Please check the website structure.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decfad4",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.   \n",
    "A) Book name   \n",
    "B) Author name   \n",
    "C) Volumes sold   \n",
    "D) Publisher   \n",
    "E) Genre   \n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bae5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6453550a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Book Name       Author Name  \\\n",
      "0                                   Da Vinci Code,The        Brown, Dan   \n",
      "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "4                                Fifty Shades of Grey      James, E. L.   \n",
      "..                                                ...               ...   \n",
      "95                                          Ghost,The    Harris, Robert   \n",
      "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes Sold        Publisher                        Genre  \n",
      "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "1     4,475,152       Bloomsbury           Children's Fiction  \n",
      "2     4,200,654       Bloomsbury           Children's Fiction  \n",
      "3     4,179,479       Bloomsbury           Children's Fiction  \n",
      "4     3,758,936     Random House              Romance & Sagas  \n",
      "..          ...              ...                          ...  \n",
      "95      807,311     Random House   General & Literary Fiction  \n",
      "96      794,201          Penguin        Food & Drink: General  \n",
      "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "98      791,507            Orion           Biography: General  \n",
      "99      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"in-article sortable\")\n",
    "\n",
    "book_name = []\n",
    "author_name = []\n",
    "volumes_sold = []\n",
    "publisher = []\n",
    "genre = []\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5:\n",
    "        book_name.append(columns[1].text.strip())\n",
    "        author_name.append(columns[2].text.strip())\n",
    "        volumes_sold.append(columns[3].text.strip())\n",
    "        publisher.append(columns[4].text.strip())\n",
    "        genre.append(columns[5].text.strip())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Book Name\": book_name,\n",
    "    \"Author Name\": author_name,\n",
    "    \"Volumes Sold\": volumes_sold,\n",
    "    \"Publisher\": publisher,\n",
    "    \"Genre\": genre\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c95218",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.   \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details:   \n",
    "A) Name   \n",
    "B) Year span   \n",
    "C) Genre   \n",
    "D) Run time   \n",
    "E) Ratings   \n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff891ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    tv_series = soup.find_all(\"div\", class_=\"lister-item mode-detail\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for tv in tv_series:\n",
    "        name = tv.find(\"h3\", class_=\"lister-item-header\").a.text\n",
    "\n",
    "        year_span = tv.find(\"span\", class_=\"lister-item-year text-muted unbold\").text\n",
    "\n",
    "        genre = tv.find(\"span\", class_=\"genre\").text.strip()\n",
    "\n",
    "        run_time = tv.find(\"span\", class_=\"runtime\").text\n",
    "\n",
    "        rating = tv.find(\"div\", class_=\"ipl-rating-star small\").span.text\n",
    "\n",
    "        votes = tv.find(\"span\", name=\"nv\").text\n",
    "\n",
    "        data.append({\n",
    "            \"Name\": name,\n",
    "            \"Year span\": year_span,\n",
    "            \"Genre\": genre,\n",
    "            \"Run time\": run_time,\n",
    "            \"Rating\": rating,\n",
    "            \"Votes\": votes\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df.to_csv(\"imdb_tv_series.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eec3f5",
   "metadata": {},
   "source": [
    "\n",
    "8. Details of Datasets from UCI machine learning repositories.   \n",
    "Url = https://archive.ics.uci.edu/  You \n",
    "have to find the following details:   \n",
    "A) Dataset name   \n",
    "B) Data type   \n",
    "C) Task   \n",
    "D) Attribute type   \n",
    "E) No of instances   \n",
    "F) No of attribute G) Year  \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e30b8659",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2066455926.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_13484\\2013000462.py:11: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b20407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
